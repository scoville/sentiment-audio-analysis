{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "May be file is so short:  auditary_emotion_recognition/IEMOCAP_full_release/Session1/sentences/wav/Ses01M_script03_1/Ses01M_script03_1_M000.wav\n",
      "May be file is so short:  auditary_emotion_recognition/IEMOCAP_full_release/Session3/sentences/wav/Ses03F_impro04/Ses03F_impro04_F026.wav\n",
      "May be file is so short:  auditary_emotion_recognition/IEMOCAP_full_release/Session1/sentences/wav/Ses01M_script01_2/Ses01M_script01_2_M011.wav\n",
      "May be file is so short:  auditary_emotion_recognition/IEMOCAP_full_release/Session1/sentences/wav/Ses01M_impro02/Ses01M_impro02_F008.wav\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/core/_methods.py:29: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_minimum(a, axis, None, out, keepdims)\n",
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/lib/function_base.py:4291: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "May be file is so short:  auditary_emotion_recognition/IEMOCAP_full_release/Session1/sentences/wav/Ses01M_impro06/Ses01M_impro06_M029.wav\n",
      "task...\n",
      "May be file is so short:  auditary_emotion_recognition/IEMOCAP_full_release/Session1/sentences/wav/Ses01F_script01_3/Ses01F_script01_3_F010.wav\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "May be file is so short:  auditary_emotion_recognition/IEMOCAP_full_release/Session3/sentences/wav/Ses03M_impro06/Ses03M_impro06_F014.wav\n",
      "May be file is so short:  auditary_emotion_recognition/IEMOCAP_full_release/Session1/sentences/wav/Ses01F_script02_2/Ses01F_script02_2_F024.wav\n",
      "May be file is so short:  auditary_emotion_recognition/IEMOCAP_full_release/Session3/sentences/wav/Ses03M_impro06/Ses03M_impro06_M023.wav\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/core/_methods.py:29: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_minimum(a, axis, None, out, keepdims)\n",
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/lib/function_base.py:4291: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task...\n",
      "May be file is so short:  auditary_emotion_recognition/IEMOCAP_full_release/Session2/sentences/wav/Ses02M_impro06/Ses02M_impro06_F018.wav\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "May be file is so short:  auditary_emotion_recognition/IEMOCAP_full_release/Session1/sentences/wav/Ses01F_script02_1/Ses01F_script02_1_F001.wav\n",
      "May be file is so short:  auditary_emotion_recognition/IEMOCAP_full_release/Session3/sentences/wav/Ses03F_impro02/Ses03F_impro02_F012.wav\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "May be file is so short:  auditary_emotion_recognition/IEMOCAP_full_release/Session3/sentences/wav/Ses03F_impro02/Ses03F_impro02_M011.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/core/_methods.py:29: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_minimum(a, axis, None, out, keepdims)\n",
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/lib/function_base.py:4291: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task...\n",
      "task...\n",
      "task...\n",
      "May be file is so short:  auditary_emotion_recognition/IEMOCAP_full_release/Session3/sentences/wav/Ses03F_impro02/Ses03F_impro02_M015.wav\n",
      "May be file is so short:  auditary_emotion_recognition/IEMOCAP_full_release/Session3/sentences/wav/Ses03M_impro06/Ses03M_impro06_M002.wav\n",
      "task...\n",
      "task...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/core/_methods.py:29: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_minimum(a, axis, None, out, keepdims)\n",
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/lib/function_base.py:4291: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/core/_methods.py:29: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_minimum(a, axis, None, out, keepdims)\n",
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/lib/function_base.py:4291: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May be file is so short:  auditary_emotion_recognition/IEMOCAP_full_release/Session1/sentences/wav/Ses01F_script02_2/Ses01F_script02_2_M043.wav\n",
      "task...\n",
      "task...\n",
      "May be file is so short:  auditary_emotion_recognition/IEMOCAP_full_release/Session1/sentences/wav/Ses01F_script02_2/Ses01F_script02_2_M049.wav\n",
      "May be file is so short:  auditary_emotion_recognition/IEMOCAP_full_release/Session3/sentences/wav/Ses03M_impro08b/Ses03M_impro08b_F020.wav\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/core/_methods.py:29: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_minimum(a, axis, None, out, keepdims)\n",
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/lib/function_base.py:4291: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/core/_methods.py:29: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_minimum(a, axis, None, out, keepdims)\n",
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/lib/function_base.py:4291: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task...\n",
      "task...\n",
      "task...\n",
      "May be file is so short:  auditary_emotion_recognition/IEMOCAP_full_release/Session5/sentences/wav/Ses05M_impro02/Ses05M_impro02_F008.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May be file is so short:  auditary_emotion_recognition/IEMOCAP_full_release/Session4/sentences/wav/Ses04M_script01_2/Ses04M_script01_2_M007.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/core/_methods.py:29: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_minimum(a, axis, None, out, keepdims)\n",
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "/home/vuthede/.local/lib64/python3.6/site-packages/numpy/lib/function_base.py:4291: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "task...\n",
      "May be file is so short:  auditary_emotion_recognition/IEMOCAP_full_release/Session5/sentences/wav/Ses05M_script02_2/Ses05M_script02_2_F038.wav\n",
      "task...\n",
      "task...\n",
      "Finished creating input output into txt file\n",
      "len input and output: 10018 ,  10018\n",
      "Finish write processed data (input, output) to file!!!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os.path import basename\n",
    "import audiosegment\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import sys\n",
    "import numpy\n",
    "\n",
    "import librosa\n",
    "import pickle\n",
    "import acousticFeatures\n",
    "\n",
    "\n",
    "#Constant\n",
    "EMOTION_ANNOTATORS = {'anger': 0, 'happiness' : 1, 'sadness' : 2, 'neutral' : 3, 'frustration' : 4, 'excited': 5,\n",
    "           'fear' : 6,'surprise' : 7,'disgust' : 8, 'other' : 9}\n",
    "\n",
    "EMOTION = {'ang': 0, 'hap' : 1, 'sad' : 2, 'neu' : 3, 'fru' : 4, 'exc': 5,\n",
    "           'fea' : 6,'sur' : 7,'dis' : 8, 'oth' : 9, 'xxx':10}\n",
    "\n",
    "METHOD = {'audio_feature':0, 'LSTM':1}\n",
    "\n",
    "#Method for classification\n",
    "method = METHOD['audio_feature']\n",
    "\n",
    "\n",
    "isRawDataProcessed = False\n",
    "\n",
    "#Development mode. Only run with small data.\n",
    "dev = False\n",
    "\n",
    "onlyAcoustic = True\n",
    "\n",
    "\n",
    "#Define class\n",
    "class Input:\n",
    "    ##spectral, prosody, erergy are dict type\n",
    "    def __init__(self, spectral=None, prosody=None, energy=None, spectrogram=None, acoustic_features=None):\n",
    "        self.spectral = spectral\n",
    "        self.prosody = prosody\n",
    "        self.energy = energy\n",
    "        self.spectrogram = spectrogram\n",
    "        self.onlyAcoustic = onlyAcoustic\n",
    "        self.acoustic_features = acoustic_features\n",
    "        \n",
    "    def print(self):\n",
    "        print(\"spectral  features: \", spectral)\n",
    "        print(\"prosody features: \", prosody)\n",
    "        print(\"energy: \", energy)\n",
    "        print(\"spectrogram: \", spectrogram)\n",
    "        \n",
    "    def input2Vec(self, onlySpectrogram, onlyAcoustic):\n",
    "        \n",
    "        if (onlySpectrogram ==  False):\n",
    "            features = []\n",
    "            if (onlyAcoustic == False):\n",
    "                s = list(self.spectral.values())\n",
    "                p = list(self.prosody.values())\n",
    "                e = list(self.energy.values())\n",
    "                [features.extend(x) for x in [s, p, e]]\n",
    "            else:\n",
    "                features = self.acoustic_features\n",
    "               # print(\"fea:\", features)\n",
    "            return features\n",
    "        else :\n",
    "            return self.spectrogram\n",
    "    \n",
    "class Output:\n",
    "    def __init__(self, VAD):\n",
    "        self.VAD = VAD\n",
    "        \n",
    "    def output2Vec(self):\n",
    "        return self.VAD\n",
    "    \n",
    "    \n",
    "    \n",
    "#Functions for get features from audio file\n",
    "def amp2Db(samples):\n",
    "    dbs = []\n",
    "    for  x in samples:\n",
    "        if x < 0:\n",
    "            v = - dspUtil.rmsToDb(np.abs(x))\n",
    "        elif x == 0:\n",
    "            v = 0\n",
    "        else :\n",
    "            v = dspUtil.rmsToDb(np.abs(x))\n",
    "        dbs.append(v)\n",
    "    return dbs\n",
    "\n",
    "def getF0Features(file):\n",
    "    features = {}\n",
    "    sound = audiosegment.from_file(file)\n",
    "    voiced = sound.filter_silence(duration_s=0.2)\n",
    "    frame_rate = sound.frame_rate\n",
    "    frames = sound.dice(0.032)\n",
    "\n",
    "    f0s = []\n",
    "    for f in frames:\n",
    "        f0 = dspUtil.calculateF0once(amp2Db(f.get_array_of_samples()), frame_rate)\n",
    "        if(f0 != 0):\n",
    "            f0s.append(f0)\n",
    "    \n",
    "    features['f0_min'] = np.min(f0s)\n",
    "    features['f0_max'] = np.max(f0s)\n",
    "    features['f0_range'] = np.max(f0s) - np.min(f0s)\n",
    "    features['f0_mean'] = np.mean(f0s)\n",
    "    features['f0_median'] = np.median(f0s)\n",
    "    features['f0_25th'] = np.percentile(f0s, 25)\n",
    "    features['f0_75th'] = np.percentile(f0s, 75)\n",
    "    features['f0_std'] = np.std(f0s)\n",
    "    \n",
    "  \n",
    "    return features\n",
    "\n",
    "def getEnergyFeatures(file):\n",
    "    features = {}\n",
    "    sound = audiosegment.from_file(file)\n",
    "    voiced = sound.filter_silence(duration_s=0.2)\n",
    "    samples = voiced.get_array_of_samples()\n",
    "    frame_rate = sound.frame_rate\n",
    "    frames = sound.dice(0.032)\n",
    "    \n",
    "    e = []\n",
    "    for f in frames:\n",
    "        e.append(np.abs(f.max_dBFS))\n",
    "    \n",
    "    \n",
    "    features['energy_min'] = np.min(e)\n",
    "    features['energy_max'] = np.max(e)\n",
    "    features['energy_range'] = np.max(e) - np.min(e)\n",
    "    features['energy_mean'] = np.mean(e)\n",
    "    features['energy_median'] = np.median(e)\n",
    "    features['energy_25th'] = np.percentile(e, 25)\n",
    "    features['energy_75th'] = np.percentile(e, 75)\n",
    "    features['energy_std'] = np.std(e)   \n",
    "\n",
    "    return features\n",
    "    \n",
    "def audio2Features(file):\n",
    "    spectral = {}\n",
    "    prosody = {}\n",
    "    energy = {}\n",
    "    try:\n",
    "        if (onlyAcoustic == False):\n",
    "            prosody = getF0Features(file)\n",
    "            energy = getEnergyFeatures(file)\n",
    "            y, sr = librosa.load(file)\n",
    "            spectrogram = librosa.stft(y)\n",
    "            spectrogram = np.abs(spectrogram)\n",
    "            #To be continued....\n",
    "            return Input(spectral, prosody, energy, spectrogram)\n",
    "        else :\n",
    "            acoustic_features = acousticFeatures.getAllFeatures(file)\n",
    "            return Input(acoustic_features = acoustic_features)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "#Function for getting input vector and corresponding output      \n",
    "def parallel_task(d0, d1):\n",
    "    print(\"task...\")\n",
    "    # Each input diectory contains many file\n",
    "    # This fucntion will walk through all valid 'wav'files in this directory and get features like engergy, frequency...\n",
    "    def parseInput(dir):\n",
    "        dicts = {} \n",
    "        for f in os.listdir(dir):\n",
    "            if not f.startswith(\".\") and os.path.splitext(f)[1] == \".wav\":\n",
    "                dicts[os.path.splitext(f)[0]] = audio2Features(dir + \"/\" + f)\n",
    "\n",
    "\n",
    "        return dicts\n",
    "    \n",
    "    # Each output file contains label of many diffrent 'wav' file.\n",
    "    # This function will parse content of text file using 'regrex'. Then turn it into label\n",
    "    def parseOutput(file):\n",
    "        dict_namefile_output = {}\n",
    "        # Open file to get all contents excepts the first line.\n",
    "        f = open(file, 'r')\n",
    "        content = \"\"\n",
    "        index = 0\n",
    "        for line in f:\n",
    "            index = index + 1\n",
    "            if index == 1:\n",
    "                continue\n",
    "            content  = content + line\n",
    "\n",
    "        # Find all matched patterns in the content\n",
    "        ps = re.findall(r'\\[.*?\\)\\n\\n', content, re.DOTALL)\n",
    "\n",
    "        # Parse each matched pattern into  'Output' object\n",
    "        try:\n",
    "            for p in ps:\n",
    "                ls = p.split(\"\\n\")\n",
    "                ls = list(filter(lambda x: len(x) > 0 ,ls))\n",
    "\n",
    "                # Split elements of the first line which looks like : \n",
    "                # [147.0300 - 151.7101]\tSes01F_impro02_M012\tneu\t[2.5000, 2.0000, 2.0000]\n",
    "                ele_line0 = re.search(r'(\\[.*?\\])(\\s)(.*?)(\\s)(.*?)(\\s)(\\[.*?\\])', ls[0]).groups()\n",
    "\n",
    "                # Split time components which looks like:\n",
    "                # [147.0300 - 151.7101]\n",
    "                time_dur = ele_line0[0]\n",
    "                ele_time_dur = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", time_dur)\n",
    "                ele_time_dur = [float(x) for x in ele_time_dur]\n",
    "\n",
    "                # Get code and category_origin which looks like:\n",
    "                # Code: Ses01F_impro02_M012\n",
    "                # Category_origin: neu\n",
    "                code = ele_line0[2]\n",
    "                category_origin = ele_line0[4]\n",
    "\n",
    "                # Split attribute components which looks like:\n",
    "                # [2.5000, 2.0000, 2.0000]\n",
    "                attribute = ele_line0[6]\n",
    "                ele_attribute = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", attribute)\n",
    "                ele_attribute = [float(x) for x in ele_attribute]\n",
    "\n",
    "                # Get categorial_evaluation:\n",
    "                lines_categorical = list(filter(lambda x : x[0] == 'C', ls))\n",
    "                rex = re.compile(r'C.*?:(\\s)(.*?)(\\s)\\(.*?\\)')\n",
    "\n",
    "                category_evaluation = []\n",
    "                for l in lines_categorical:\n",
    "                    elements = rex.search(l).groups()\n",
    "                    cat = elements[1]\n",
    "                    cat = cat.split(\";\")\n",
    "                    cat = map(lambda x: x.lstrip(), cat)\n",
    "                    cat = list(filter(lambda x: len(x)>0, cat))\n",
    "                    category_evaluation.extend(cat)\n",
    "\n",
    "\n",
    "                # Make list distinct\n",
    "                category_evaluation = np.array(category_evaluation)\n",
    "                #category_evaluation = list(set(category_evaluation))\n",
    "                \n",
    "                \n",
    "\n",
    "                # Make dict {name_file : parsed_output}\n",
    "                dict_namefile_output[code] = Output(ele_attribute)\n",
    "            return dict_namefile_output\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    ### Parse input and output files and get input and output as vector\n",
    "    dicts_in = parseInput(d0)\n",
    "    dicts_out = parseOutput(d1)\n",
    "    in_out = []\n",
    "    \n",
    "    keys = list(dicts_in.keys())\n",
    "    for key in keys:\n",
    "        if (method == METHOD['LSTM']):\n",
    "            in_out.append((dicts_in[key].input2Vec(onlySpectrogram=True,onlyAcoustic=False), dicts_out[key].output2Vec()))\n",
    "        else:\n",
    "            value = dicts_in[key].input2Vec(onlySpectrogram=False, onlyAcoustic=True)\n",
    "            if(value.all() != None ):\n",
    "                in_out.append((value, dicts_out[key].output2Vec()))\n",
    "    return in_out\n",
    "    \n",
    "    \n",
    "def createInput_Output():\n",
    "    ### Get directories of input and output\n",
    "    DATA_DIR = \"auditary_emotion_recognition/IEMOCAP_full_release\"\n",
    "    NUM_SESSION = 5\n",
    "    input_output = []\n",
    "    for i in range (1, NUM_SESSION + 1):\n",
    "        name_session = \"Session\" + str(i)\n",
    "        root_dir_of_wav = DATA_DIR + \"/\" + name_session + \"/sentences\" + \"/wav\"\n",
    "        root_dir_of_labels = DATA_DIR + \"/\" + name_session + \"/dialog\" + \"/EmoEvaluation\"\n",
    "\n",
    "        for x in os.walk(root_dir_of_wav):\n",
    "            if(x[0] == root_dir_of_wav):\n",
    "                dirs_of_wav = x[1]\n",
    "                index = -1\n",
    "            else:\n",
    "                index = index + 1\n",
    "                input_output.append((x[0], root_dir_of_labels + \"/\" + dirs_of_wav[index] + \".txt\"))\n",
    "                \n",
    "    \n",
    "    ds = input_output\n",
    "    in_out = []\n",
    "    input = []\n",
    "    out = []\n",
    "    \n",
    "    # Multi processing\n",
    "    with Pool(processes=32) as pool:\n",
    "         in_out = pool.starmap(parallel_task, ds)\n",
    "   \n",
    "    r = []\n",
    "    for e in in_out:\n",
    "        r = r + e\n",
    "    \n",
    "    input = [x[0] for x in r]\n",
    "    out = [x[1] for x in r]\n",
    "    print(\"Finished creating input output into txt file\")\n",
    "    print(\"len input and output:\", len(input), \", \", len(out))\n",
    "    return (input, out)\n",
    " \n",
    "\n",
    "\n",
    "#If have not processed data yet then process, otherwise loading data from file.\n",
    "if isRawDataProcessed == False:\n",
    "\n",
    "    ##Get input, normalize input, get output\n",
    "    input, output = createInput_Output()\n",
    "    output = np.array(output)\n",
    "    \n",
    "    if(method == METHOD['audio_feature']):\n",
    "        input = np.array(input)\n",
    "       # input = input / input.max(axis=0)\n",
    "        filehandlerInput = open('processed-data/input_VAD.obj', 'wb')\n",
    "        filehandlerOutput = open('processed-data/output_VAD.obj', 'wb')\n",
    "    \n",
    "        \n",
    "    pickle.dump(input, filehandlerInput)\n",
    "    pickle.dump(output, filehandlerOutput)\n",
    "    print(\"Finish write processed data (input, output) to file!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3.6",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
